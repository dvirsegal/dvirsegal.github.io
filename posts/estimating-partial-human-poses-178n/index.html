<!DOCTYPE html>
<html lang="en">

<head>
  <title>
  Estimating partial human poses · dvirsegal
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Dvir Segal">
<meta name="description" content="A lot has been said on OpenPose. This real-time multi-person groundbreaking keypoints detection method has many features, along with:
2D real-time multi-person keypoint detection 3D real-time single-person keypoint detection Calibration toolbox Single-person tracking Supporting Python API, Unity Plugin, Cuda, OpenCL, and CPU only Moreover, more features are in the works by the team (Gines Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Hanbyul Joo, Yaser Sheikh, and Yaadhav Raaj) at Carnegie Mellon University.">
<meta name="keywords" content="blog,developer,personal">

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Estimating partial human poses"/>
<meta name="twitter:description" content="A lot has been said on OpenPose. This real-time multi-person groundbreaking keypoints detection method has many features, along with:
2D real-time multi-person keypoint detection 3D real-time single-person keypoint detection Calibration toolbox Single-person tracking Supporting Python API, Unity Plugin, Cuda, OpenCL, and CPU only Moreover, more features are in the works by the team (Gines Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Hanbyul Joo, Yaser Sheikh, and Yaadhav Raaj) at Carnegie Mellon University."/>

<meta property="og:title" content="Estimating partial human poses" />
<meta property="og:description" content="A lot has been said on OpenPose. This real-time multi-person groundbreaking keypoints detection method has many features, along with:
2D real-time multi-person keypoint detection 3D real-time single-person keypoint detection Calibration toolbox Single-person tracking Supporting Python API, Unity Plugin, Cuda, OpenCL, and CPU only Moreover, more features are in the works by the team (Gines Hidalgo, Zhe Cao, Tomas Simon, Shih-En Wei, Hanbyul Joo, Yaser Sheikh, and Yaadhav Raaj) at Carnegie Mellon University." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://dvirsegal.github.io/posts/estimating-partial-human-poses-178n/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-05-31T00:00:00+00:00" />
<meta property="article:modified_time" content="2019-05-31T00:00:00+00:00" />





<link rel="canonical" href="https://medium.com/@dvirsegal/estimating-partial-human-poses-d1548a4a9080">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.577e3c5ead537873430da16f0964b754a120fd87c4e2203a00686e7c75b51378.css" integrity="sha256-V348Xq1TeHNDDaFvCWS3VKEg/YfE4iA6AGhufHW1E3g=" crossorigin="anonymous" media="screen" />






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css" integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin="anonymous" media="screen" />
  



 
  
    
    <link rel="stylesheet" href="/css/custom.min.0c266ef02d8b41f01746f0dd720ba3e239e36a974a63641bee33b0bdddb6b287.css" integrity="sha256-DCZu8C2LQfAXRvDdcguj4jnjapdKY2Qb7jOwvd22soc=" crossorigin="anonymous" media="screen" />
  

  
    
    <link rel="stylesheet" href="/css/font.min.227f65169235f7e8ae52f7f3199c2b98c67c043c04c31c46e7b18bb3f78c2bfd.css" integrity="sha256-In9lFpI19&#43;iuUvfzGZwrmMZ8BDwEwxxG57GLs/eMK/0=" crossorigin="anonymous" media="screen" />
  





<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/dvir_animated.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/dvir_animated.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      dvirsegal
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/about/">About</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://dvirsegal.github.io/posts/estimating-partial-human-poses-178n/">
              Estimating partial human poses
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2019-05-31T00:00:00Z">
                May 31, 2019
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              4-minute read
            </span>
          </div>
          <div class="authors">
  <i class="fa-solid fa-user" aria-hidden="true"></i>
    <a href="/authors/dvir-segal/">Dvir Segal</a></div>

          
          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/machine-learning/">machine-learning</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/openpose/">openpose</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/tensorflow/">tensorflow</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/deep-learning/">deep-learning</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
          <img src="https://cdn-images-1.medium.com/max/800/0*IVJ6dqAjTl9oy3b9.JPG" alt="Featured image"/>
        
        <p>A lot has been said on <a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose"  class="external-link" target="_blank" rel="noopener">OpenPose</a>. This real-time multi-person groundbreaking keypoints detection method has many features, along with:</p>
<ul>
<li>2D real-time multi-person keypoint detection</li>
<li>3D real-time single-person keypoint detection</li>
<li>Calibration toolbox</li>
<li>Single-person tracking</li>
<li>Supporting Python API, Unity Plugin, Cuda, OpenCL, and CPU only</li>
</ul>
<p>Moreover, more features are in the works by the team (<a href="https://www.gineshidalgo.com/"  class="external-link" target="_blank" rel="noopener">Gines Hidalgo</a>, <a href="https://people.eecs.berkeley.edu/~zhecao"  class="external-link" target="_blank" rel="noopener">Zhe Cao</a>, <a href="http://www.cs.cmu.edu/~tsimon"  class="external-link" target="_blank" rel="noopener">Tomas Simon</a>, <a href="https://scholar.google.com/citations?user=sFQD3k4AAAAJ&amp;hl=en"  class="external-link" target="_blank" rel="noopener">Shih-En Wei</a>, <a href="https://jhugestar.github.io/"  class="external-link" target="_blank" rel="noopener">Hanbyul Joo</a>, <a href="http://www.cs.cmu.edu/~yaser"  class="external-link" target="_blank" rel="noopener">Yaser Sheikh</a>, and <a href="https://www.raaj.tech/"  class="external-link" target="_blank" rel="noopener">Yaadhav Raaj</a>) at <a href="https://www.cmu.edu/"  class="external-link" target="_blank" rel="noopener">Carnegie Mellon University</a>. The below link is being updated occasionally for new frameworks’ changes. Besides, it contains an installation guide, troubleshooting, and a quick start section. So, go ahead, have a look, and play with it.</p>
<p>[<strong>CMU-Perceptual-Computing-Lab/openpose</strong>](<a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose"  class="external-link" target="_blank" rel="noopener">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a> &ldquo;<a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose"  class="external-link" target="_blank" rel="noopener">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a>)</p>
<h4 id="what-">
  What 🙋?
  <a class="heading-link" href="#what-">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>One of the caveats of OpenPose framework is to identify a partial human image as determined by my Master’s supervisor, Professor <a href="https://cs.haifa.ac.il/~hagit/"  class="external-link" target="_blank" rel="noopener">Hagit Hel-Or</a>. The system’s model was trained on human figures taken from several <a href="http://domedb.perception.cs.cmu.edu/"  class="external-link" target="_blank" rel="noopener">datasets</a> (<a href="http://cocodataset.org/"  class="external-link" target="_blank" rel="noopener">COCO</a> and <a href="http://human-pose.mpi-inf.mpg.de/"  class="external-link" target="_blank" rel="noopener">MPII</a>), while the images contain different people on various backgrounds, most of them don’t include only “part” of a person image (for example, only shoulders).</p>
<p>It means the algorithm fails to identify the connected graph of all identified body parts. While a body <strong>part</strong> is an element of the human body (like hand, neck, hip) and a <strong>pair</strong> is two connected parts.</p>
<p>The image below, taken from the excellent Medium blog-posts <a href="https://arvrjourney.com/human-pose-estimation-using-openpose-with-tensorflow-part-1-7dd4ca5c8027"  class="external-link" target="_blank" rel="noopener">series</a> by <a href="https://medium.com/u/e34ee48c0a61"  class="external-link" target="_blank" rel="noopener">Ale Solano</a> displays the skeletons as represented by the COCO dataset (pairs and parts):




<div style="text-align: center;">
    <img src="https://cdn-images-1.medium.com/max/800/1*BJQRrQGuW8VLH8MfA9ZngQ.png" alt="Parts and Pairs indexes for COCO dataset" style="display: block; margin: 0 auto;" />
    <p style="margin: 0; text-align: center;"><em>Parts and Pairs indexes for COCO dataset</em></p>
</div>
</p>
<p>I recommend reading <a href="https://medium.com/u/e34ee48c0a61"  class="external-link" target="_blank" rel="noopener">Ale Solano</a>’s series for more details on OpenPose pipeline which I don’t plan to drill down into as part of this blog-post.</p>
<p>My goal in this opensource project is to allow using the vast capabilities of OpenPose system on images containing only partial body parts. The following GIF emphasizes the framework’s limitation:</p>




<div style="text-align: center;">
    <img src="https://cdn-images-1.medium.com/max/800/0*Lmi9odoXsT1PE3EI.gif" alt="OpenPose Limitation" style="display: block; margin: 0 auto;" />
    <p style="margin: 0; text-align: center;"><em>OpenPose Limitation</em></p>
</div>

<h4 id="why-">
  Why 🤷?
  <a class="heading-link" href="#why-">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>I intended to learn various concepts to enrich my technical stack, like using machine learning, get a better understanding of computer vision concepts, and using OpenPose. I did all the above while having fun and eventually contributing to the opensource community.</p>
<p>As a side effect, by sorting out OpenPose limitation, it may help other researchers who hesitate using it.</p>
<p>Say, for example, you would like to identify a person’s key points, or as said in the computer vision jargon, skeleton. However, the image appears cut or intentionally contains only part of the human body. One application may be for physical therapy to identify treatment improvements. More usages exist depending on the user’s purpose.</p>
<h4 id="how-">
  How 🤓?
  <a class="heading-link" href="#how-">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h4>
<p>The proposed method (credit to my Master’s supervisor) is to add the missing body part into the image <strong><em>wisely</em></strong>. Afterward, run the OpenPose framework on the reconstructed image. The result is then manipulated to show the skeleton on the original body image.</p>
<p><strong>The following images show the algorithm flow on an original image of human legs:</strong></p>
<ol>
<li>A partial (legs) image is given</li>
<li>An upper (dummy) image is matched to the original body part, and a merged image is created</li>
<li>An OpenPose skeleton is generated for the combined image</li>
<li>The skeleton result is reduced to the original image only</li>
</ol>
<p>As can be seen below:</p>




<div style="text-align: center;">
    <img src="https://cdn-images-1.medium.com/max/800/0*IVJ6dqAjTl9oy3b9.JPG" alt="Algorithm flow from left to right" style="display: block; margin: 0 auto;" />
    <p style="margin: 0; text-align: center;"><em>Algorithm flow from left to right</em></p>
</div>

<p>The reconstructed image is created by first identifying the object in the original image, using a <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb"  class="external-link" target="_blank" rel="noopener">tensorflow trained model</a> (DetecorAPI with <a href="https://arxiv.org/abs/1506.01497"  class="external-link" target="_blank" rel="noopener">faster_rcnn</a>) based on COCO dataset. The model returns a bounding box of the detected object. Then by using the box’s dimensions, the dummy image is being manipulated to the original image characteristics by an affine transformation.</p>
<p>Eventually, the two images are being stitched together, and OpenPose is being triggered on the new image.</p>
<p>The below video demonstrate the result of a walking person video:</p>




<div style="text-align: center;">
    <img src="https://cdn-images-1.medium.com/max/800/0*N9-JdRI9VmTtWIGa.gif" alt="Original Video" style="display: block; margin: 0 auto;" />
    <p style="margin: 0; text-align: center;"><em>Original Video</em></p>
</div>





<div style="text-align: center;">
    <img src="https://cdn-images-1.medium.com/max/800/0*dOPab9YXD4QjqHsg.gif" alt="Skeletonized Video" style="display: block; margin: 0 auto;" />
    <p style="margin: 0; text-align: center;"><em>Skeletonized Video</em></p>
</div>

<p>To sum up, OpenPose has great potential for endless applications, enabling motion detection without dedicated hardware like Kinect, a 2D camera is enough. Overcoming on one of the framework limitations can step us forward for that goal, and this is the real power of the opensource community.</p>
<p>I hope you’ll find it interesting (👏).</p>
<p>The project’s code can be found here:</p>
<p><a href="https://github.com/DeJaVoo/partial-openpose"  class="external-link" target="_blank" rel="noopener"><strong>DeJaVoo/partial-openpose</strong></a></p>

      </div>


      <footer>
        


        
        
        
        
        

        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2019 -
    
    2024
     Dvir Segal 
    ·
    
    Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js" integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script>
  

  

  


  

  

  

  <script data-goatcounter="https://dvirsegal.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>


  

  

  

  

  

  

  

  

  

  

  
</body>

</html>
